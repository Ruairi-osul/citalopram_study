{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ephys_queries import db_setup_core, select_spike_times, select_discrete_data\n",
    "from spiketimes.df.binning import spike_count_around_event_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\".\").absolute().parent / \"data\"\n",
    "group_names = (\"chronic_citalopram\", \n",
    "                           \"chronic_saline\", \n",
    "                           \"chronic_saline_\", \n",
    "                           \"citalopram_continuation\", \n",
    "                           \"citalopram_discontinuation\")\n",
    "dfb = (\n",
    "    pd.read_csv(data_dir / \"baseline.csv\")\n",
    "    .assign(group= \n",
    "            lambda x: x[\"group_name\"].map({\"chronic_saline\": \"CS\",\n",
    "                                          \"chronic_saline_\": \"CS\",\n",
    "                                          \"citalopram_continuation\": \"CC\",\n",
    "                                          \"chronic_citalopram\": \"CC\",\n",
    "                                          \"citalopram_discontinuation\": \"CD\"})\n",
    "           )\n",
    "    .loc[lambda x: x.group_name.isin(group_names)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_name = \"base_shock\"\n",
    "fs = 30000\n",
    "load_dotenv()\n",
    "engine, metadata = db_setup_core()\n",
    "\n",
    "df_spikes = (\n",
    "    select_spike_times(\n",
    "            engine, \n",
    "            metadata,\n",
    "            group_names=group_names,\n",
    "            block_name=block_name,\n",
    "            )\n",
    "    .assign(spiketimes=lambda x: x[\"spike_time_samples\"].divide(fs))\n",
    "    .merge(dfb[[\"neuron_id\", \"session_name\"]])\n",
    ")\n",
    "\n",
    "df_events = (\n",
    "    select_discrete_data(\n",
    "            engine,\n",
    "            metadata,\n",
    "            group_names=group_names,\n",
    "            block_name=block_name\n",
    "    )\n",
    "    .assign(event_s= lambda x: x[\"timepoint_sample\"].divide(fs))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spikes = df_spikes.groupby(\"neuron_id\").filter(lambda x: len(x) >= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts =spike_count_around_event_by(\n",
    "    df_data=df_spikes,\n",
    "    binsize=0.35,\n",
    "    df_data_data_colname=\"spiketimes\",\n",
    "    df_data_group_colname=\"session_name\",\n",
    "    df_data_spiketrain_colname=\"neuron_id\",\n",
    "    df_events=df_events,\n",
    "    df_events_event_colname=\"event_s\",\n",
    "    df_events_group_colname=\"session_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr\n",
    "from spiketimes.utils import p_adjust\n",
    "\n",
    "def pearson_r(\n",
    "    df, \n",
    "    spiketrain_col=\"spiketrain\", \n",
    "    data_col=\"counts\", \n",
    "    group_col=\"session_name\",\n",
    "    adjust_p=True,\n",
    "    p_adjust_method=\"Benjamini-Hochberg\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate pearson's correlation coefficent between all pairs of\n",
    "    simultaneously-recorded spiketrains.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    sessions= df[group_col].unique()\n",
    "    for session in sessions:\n",
    "        df1 = (\n",
    "            df\n",
    "            .loc[df_counts[group_col] == session]\n",
    "        )\n",
    "        st_ids = df1[spiketrain_col].unique()\n",
    "        combs = list(combinations(st_ids, r=2))\n",
    "        res = list(map(\n",
    "            lambda x: (x[0], x[1], *pearsonr(df1[df1[spiketrain_col] == x[0]][data_col].values, \n",
    "                                        df1[df1[spiketrain_col] == x[1]][data_col].values)),\n",
    "            combs\n",
    "        ))\n",
    "        frames.append(\n",
    "            pd.DataFrame(res, \n",
    "                         columns=[\"spiketrain_1\", \"spiketrain_2\", \"r\", \"p\"]\n",
    "                        ).assign(**{group_col:session})\n",
    "        )\n",
    "    df_res = pd.concat(frames)\n",
    "    if adjust_p:\n",
    "        df_res.p = p_adjust(df_res.p)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pearson_r(df_counts, spiketrain_col=\"neuron_id\", data_col=\"counts\",\n",
    "         group_col=\"session_name\", adjust_p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done = (\n",
    "    df_res\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\", \"group\"]], left_on=\"spiketrain_1\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_1_cluster\"})\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_2\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_2_cluster\"})\n",
    "    .assign(has_sr=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_regular\") or (y.spiketrain_2_cluster== \"slow_regular\"),\n",
    "                       axis=1),\n",
    "            has_sir=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_irregular\") or (y.spiketrain_2_cluster== \"slow_irregular\"),\n",
    "                       axis=1),\n",
    "            has_ff=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"fast_firing\") or (y.spiketrain_2_cluster== \"fast_firing\"),\n",
    "                       axis=1)\n",
    "           )\n",
    "    .assign(comb= lambda x: x.apply(lambda y: \n",
    "                                    \"sr_sr\" if y.has_sr and (not y.has_sir) and (not y.has_ff)\n",
    "                                   else \"sr_sir\" if y.has_sr and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sr_ff\" if y.has_sr and (not y.has_sir) and y.has_ff\n",
    "                                   else \"sir_sir\" if (not y.has_sr) and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sir_ff\" if (not y.has_sr) and y.has_sir and y.has_ff\n",
    "                                   else \"ff_ff\", axis=1\n",
    "                                   ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done.to_csv(data_dir / \"evoked_rsc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007350441006729332"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
